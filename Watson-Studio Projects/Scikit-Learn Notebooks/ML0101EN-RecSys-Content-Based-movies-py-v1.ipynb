{
    "nbformat_minor": 2,
    "cells": [
        {
            "source": "<a href=\"https://www.bigdatauniversity.com\"><img src = \"https://ibm.box.com/shared/static/cw2c7r3o20w9zn8gkecaeyjhgw3xdgbj.png\" width = 400, align = \"center\"></a>\n\n<h1 align=center><font size = 5>CONTENT-BASED FILTERING</font></h1>",
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "source": "Recommendation systems are a collection of algorithms used to recommend items to users based on information taken from the user. These systems have become ubiquitous can be commonly seen in online stores, movies databases and job finders. In this notebook, we will explore Content-based recommendation systems and implement a simple version of one using Python and the Pandas library.",
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "source": "### Table of contents\n\n<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n- <p><a href=\"#ref1\">Acquiring the Data</a></p>\n- <p><a href=\"#ref2\">Preprocessing</a></p>\n- <p><a href=\"#ref3\">Content-Based Filtering</a></p>\n<p></p>\n</div>\n<br>",
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "source": "<a id=\"ref1\"></a>\n# Acquiring the Data",
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "source": "To acquire and extract the data, simply run the following Bash scripts:  \nDataset acquired from [GroupLens](http://grouplens.org/datasets/movielens/). Lets download the dataset. To download the data, we will use **`!wget`**. To download the data, we will use `!wget` to download it from IBM Object Storage.  \n__Did you know?__ When it comes to Machine Learning, you will likely be working with large datasets. As a business, where can you host your data? IBM is offering a unique opportunity for businesses, with 10 Tb of IBM Cloud Object Storage: [Sign up now for free](http://cocl.us/ML0101EN-IBM-Offer-CC)",
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "source": "!wget -O moviedataset.zip https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/moviedataset.zip\nprint('unziping ...')\n!unzip -o -j moviedataset.zip ",
            "cell_type": "code",
            "execution_count": null,
            "outputs": [],
            "metadata": {}
        },
        {
            "source": "Now you're ready to start working with the data!",
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "source": "<a id=\"ref2\"></a>\n# Preprocessing",
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "source": "First, let's get all of the imports out of the way:",
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "source": "#Dataframe manipulation library\nimport pandas as pd\n#Math functions, we'll only need the sqrt function so let's import only that\nfrom math import sqrt\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline",
            "cell_type": "code",
            "execution_count": null,
            "outputs": [],
            "metadata": {}
        },
        {
            "source": "Now let's read each file into their Dataframes:",
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "source": "#Storing the movie information into a pandas dataframe\nmovies_df = pd.read_csv('movies.csv')\n#Storing the user information into a pandas dataframe\nratings_df = pd.read_csv('ratings.csv')\n#Head is a function that gets the first N rows of a dataframe. N's default is 5.\nmovies_df.head()",
            "cell_type": "code",
            "execution_count": null,
            "outputs": [],
            "metadata": {}
        },
        {
            "source": "Let's also remove the year from the __title__ column by using pandas' replace function and store in a new __year__ column.",
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "source": "#Using regular expressions to find a year stored between parentheses\n#We specify the parantheses so we don't conflict with movies that have years in their titles\nmovies_df['year'] = movies_df.title.str.extract('(\\(\\d\\d\\d\\d\\))',expand=False)\n#Removing the parentheses\nmovies_df['year'] = movies_df.year.str.extract('(\\d\\d\\d\\d)',expand=False)\n#Removing the years from the 'title' column\nmovies_df['title'] = movies_df.title.str.replace('(\\(\\d\\d\\d\\d\\))', '')\n#Applying the strip function to get rid of any ending whitespace characters that may have appeared\nmovies_df['title'] = movies_df['title'].apply(lambda x: x.strip())\nmovies_df.head()",
            "cell_type": "code",
            "execution_count": null,
            "outputs": [],
            "metadata": {
                "scrolled": false
            }
        },
        {
            "source": "With that, let's also split the values in the __Genres__ column into a __list of Genres__ to simplify future use. This can be achieved by applying Python's split string function on the correct column.",
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "source": "#Every genre is separated by a | so we simply have to call the split function on |\nmovies_df['genres'] = movies_df.genres.str.split('|')\nmovies_df.head()",
            "cell_type": "code",
            "execution_count": null,
            "outputs": [],
            "metadata": {
                "scrolled": false
            }
        },
        {
            "source": "Since keeping genres in a list format isn't optimal for the content-based recommendation system technique, we will use the One Hot Encoding technique to convert the list of genres to a vector where each column corresponds to one possible value of the feature. This encoding is needed for feeding categorical data. In this case, we store every different genre in columns that contain either 1 or 0. 1 shows that a movie has that genre and 0 shows that it doesn't. Let's also store this dataframe in another variable since genres won't be important for our first recommendation system.",
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "source": "#Copying the movie dataframe into a new one since we won't need to use the genre information in our first case.\nmoviesWithGenres_df = movies_df.copy()\n\n#For every row in the dataframe, iterate through the list of genres and place a 1 into the corresponding column\nfor index, row in movies_df.iterrows():\n    for genre in row['genres']:\n        moviesWithGenres_df.at[index, genre] = 1\n#Filling in the NaN values with 0 to show that a movie doesn't have that column's genre\nmoviesWithGenres_df = moviesWithGenres_df.fillna(0)\nmoviesWithGenres_df.head()",
            "cell_type": "code",
            "execution_count": null,
            "outputs": [],
            "metadata": {}
        },
        {
            "source": "Next, let's look at the ratings dataframe.",
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "source": "ratings_df.head()",
            "cell_type": "code",
            "execution_count": null,
            "outputs": [],
            "metadata": {}
        },
        {
            "source": "Every row in the ratings dataframe has a user id associated with at least one movie, a rating and a timestamp showing when they reviewed it. We won't be needing the timestamp column, so let's drop it to save on memory.",
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "source": "#Drop removes a specified row or column from a dataframe\nratings_df = ratings_df.drop('timestamp', 1)\nratings_df.head()",
            "cell_type": "code",
            "execution_count": null,
            "outputs": [],
            "metadata": {}
        },
        {
            "source": "<a id=\"ref3\"></a>\n# Content-Based recommendation system",
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "source": "Now, let's take a look at how to implement __Content-Based__ or __Item-Item recommendation systems__. This technique attempts to figure out what a user's favourite aspects of an item is, and then recommends items that present those aspects. In our case, we're going to try to figure out the input's favorite genres from the movies and ratings given.\n\nLet's begin by creating an input user to recommend movies to:\n\nNotice: To add more movies, simply increase the amount of elements in the __userInput__. Feel free to add more in! Just be sure to write it in with capital letters and if a movie starts with a \"The\", like \"The Matrix\" then write it in like this: 'Matrix, The' .",
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "source": "userInput = [\n            {'title':'Breakfast Club, The', 'rating':5},\n            {'title':'Toy Story', 'rating':3.5},\n            {'title':'Jumanji', 'rating':2},\n            {'title':\"Pulp Fiction\", 'rating':5},\n            {'title':'Akira', 'rating':4.5}\n         ] \ninputMovies = pd.DataFrame(userInput)\ninputMovies",
            "cell_type": "code",
            "execution_count": null,
            "outputs": [],
            "metadata": {}
        },
        {
            "source": "#### Add movieId to input user\nWith the input complete, let's extract the input movies's ID's from the movies dataframe and add them into it.\n\nWe can achieve this by first filtering out the rows that contain the input movies' title and then merging this subset with the input dataframe. We also drop unnecessary columns for the input to save memory space.",
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "source": "#Filtering out the movies by title\ninputId = movies_df[movies_df['title'].isin(inputMovies['title'].tolist())]\n#Then merging it so we can get the movieId. It's implicitly merging it by title.\ninputMovies = pd.merge(inputId, inputMovies)\n#Dropping information we won't use from the input dataframe\ninputMovies = inputMovies.drop('genres', 1).drop('year', 1)\n#Final input dataframe\n#If a movie you added in above isn't here, then it might not be in the original \n#dataframe or it might spelled differently, please check capitalisation.\ninputMovies",
            "cell_type": "code",
            "execution_count": null,
            "outputs": [],
            "metadata": {
                "scrolled": true
            }
        },
        {
            "source": "We're going to start by learning the input's preferences, so let's get the subset of movies that the input has watched from the Dataframe containing genres defined with binary values.",
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "source": "#Filtering out the movies from the input\nuserMovies = moviesWithGenres_df[moviesWithGenres_df['movieId'].isin(inputMovies['movieId'].tolist())]\nuserMovies",
            "cell_type": "code",
            "execution_count": null,
            "outputs": [],
            "metadata": {}
        },
        {
            "source": "We'll only need the actual genre table, so let's clean this up a bit by resetting the index and dropping the movieId, title, genres and year columns.",
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "source": "#Resetting the index to avoid future issues\nuserMovies = userMovies.reset_index(drop=True)\n#Dropping unnecessary issues due to save memory and to avoid issues\nuserGenreTable = userMovies.drop('movieId', 1).drop('title', 1).drop('genres', 1).drop('year', 1)\nuserGenreTable",
            "cell_type": "code",
            "execution_count": null,
            "outputs": [],
            "metadata": {}
        },
        {
            "source": "Now we're ready to start learning the input's preferences!\n\nTo do this, we're going to turn each genre into weights. We can do this by using the input's reviews and multiplying them into the input's genre table and then summing up the resulting table by column. This operation is actually a dot product between a matrix and a vector, so we can simply accomplish by calling Pandas's \"dot\" function.",
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "source": "inputMovies['rating']",
            "cell_type": "code",
            "execution_count": null,
            "outputs": [],
            "metadata": {}
        },
        {
            "source": "#Dot produt to get weights\nuserProfile = userGenreTable.transpose().dot(inputMovies['rating'])\n#The user profile\nuserProfile",
            "cell_type": "code",
            "execution_count": null,
            "outputs": [],
            "metadata": {}
        },
        {
            "source": "Now, we have the weights for every of the user's preferences. This is known as the User Profile. Using this, we can recommend movies that satisfy the user's preferences.",
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "source": "Let's start by extracting the genre table from the original dataframe:",
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "source": "#Now let's get the genres of every movie in our original dataframe\ngenreTable = moviesWithGenres_df.set_index(moviesWithGenres_df['movieId'])\n#And drop the unnecessary information\ngenreTable = genreTable.drop('movieId', 1).drop('title', 1).drop('genres', 1).drop('year', 1)\ngenreTable.head()",
            "cell_type": "code",
            "execution_count": null,
            "outputs": [],
            "metadata": {}
        },
        {
            "source": "genreTable.shape",
            "cell_type": "code",
            "execution_count": null,
            "outputs": [],
            "metadata": {}
        },
        {
            "source": "With the input's profile and the complete list of movies and their genres in hand, we're going to take the weighted average of every movie based on the input profile and recommend the top twenty movies that most satisfy it.",
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "source": "#Multiply the genres by the weights and then take the weighted average\nrecommendationTable_df = ((genreTable*userProfile).sum(axis=1))/(userProfile.sum())\nrecommendationTable_df.head()",
            "cell_type": "code",
            "execution_count": null,
            "outputs": [],
            "metadata": {}
        },
        {
            "source": "#Sort our recommendations in descending order\nrecommendationTable_df = recommendationTable_df.sort_values(ascending=False)\n#Just a peek at the values\nrecommendationTable_df.head()",
            "cell_type": "code",
            "execution_count": null,
            "outputs": [],
            "metadata": {}
        },
        {
            "source": "Now here's the recommendation table!",
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "source": "#The final recommendation table\nmovies_df.loc[movies_df['movieId'].isin(recommendationTable_df.head(20).keys())]",
            "cell_type": "code",
            "execution_count": null,
            "outputs": [],
            "metadata": {
                "scrolled": true
            }
        },
        {
            "source": "### Advantages and Disadvantages of Content-Based Filtering\n\n##### Advantages\n* Learns user's preferences\n* Highly personalized for the user\n\n##### Disadvantages\n* Doesn't take into account what others think of the item, so low quality item recommendations might happen\n* Extracting data is not always intuitive\n* Determining what characteristics of the item the user dislikes or likes is not always obvious",
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "source": "## Want to learn more?\n\nIBM SPSS Modeler is a comprehensive analytics platform that has many machine learning algorithms. It has been designed to bring predictive intelligence to decisions made by individuals, by groups, by systems \u2013 by your enterprise as a whole. A free trial is available through this course, available here: [SPSS Modeler](http://cocl.us/ML0101EN-SPSSModeler).\n\nAlso, you can use Watson Studio to run these notebooks faster with bigger datasets. Watson Studio is IBM's leading cloud solution for data scientists, built by data scientists. With Jupyter notebooks, RStudio, Apache Spark and popular libraries pre-packaged in the cloud, Watson Studio enables data scientists to collaborate on their projects without having to install anything. Join the fast-growing community of Watson Studio users today with a free account at [Watson Studio](https://cocl.us/ML0101EN_DSX)\n\n### Thanks for completing this lesson!\n\nNotebook created by: <a href = \"https://ca.linkedin.com/in/saeedaghabozorgi\">Saeed Aghabozorgi</a>, Gabriel Garcez Barros Sousa\n\n<hr>\nCopyright &copy; 2018 [Cognitive Class](https://cocl.us/DX0108EN_CC). This notebook and its source code are released under the terms of the [MIT License](https://bigdatauniversity.com/mit-license/).\u200b",
            "cell_type": "markdown",
            "metadata": {}
        }
    ],
    "nbformat": 4,
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5",
            "name": "python3",
            "language": "python"
        },
        "widgets": {
            "state": {},
            "version": "1.1.2"
        },
        "language_info": {
            "mimetype": "text/x-python",
            "nbconvert_exporter": "python",
            "version": "3.5.5",
            "name": "python",
            "file_extension": ".py",
            "pygments_lexer": "ipython3",
            "codemirror_mode": {
                "version": 3,
                "name": "ipython"
            }
        }
    }
}